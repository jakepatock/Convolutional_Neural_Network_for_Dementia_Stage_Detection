# Convolutional_Neural_Network_for_Dementia_Stage_Detection
This project is a CNN model used to predict the stage of dementia a patient was in given a transverse MRI brain image. The dataset this model used was sourced from kaggle (link: https://www.kaggle.com/datasets/sachinkumar413/alzheimer-mri-dataset). This data set include 6400, 128 by 128 pixel, images of transverse brain MRI images of pacients with different levels of dementia. Class one was mildly demented which included 896 images of the total set. Class 2 was moderatly demented which had 64 images in the set. Class 3 was non demented which has 3200 images in the dataset. Finally, class 4 was very mild dmented which had 2240 images in the set. This dataset is not even on its class represenation. This dataset was split into 80% of the images being used as training data and 20% of the images being used as validation data and converted to a single grayscale channel tensor. The batch size used in the data loader was 64 images per batch. The strucutre of the CNN corresponed to 5 convolutional layers with a max pooling layer in between these layers. The channel sizes procedued in this order 1, 64, 128, 256, 512, and 512. The final pooling layer was flattened and connected to 3 layers of full connected linear layers. After the first two linear layers dropout of .5 was added to prevent overfitting. The size of these linear layers was as follows, 8192 neuron, 1024 neurons, 256 neurons, to 4 neurons. Cross enttropy loss was used since the model is executing multi class classification and the optimzer of choice was Adam. The model was evaluated using a weighted f1 score with a bias towards recall due to this being medical data. The model favores the occurence of false postiives in comparison with false negatives due to the medical nature of the issue at hand. False negatives can lead to dismissal of symptoms by pacients and late diagnosis of dementia potential wasting precious time that doctors could have used to slow the progression of the disease with treatment. False positives are less damaging as they lead to a closer inspection of the pacient and their symptoms. False positives can be discovered by additional analysis of symptoms and testing with little to no damage or time loss to the pacient. It is this reason on why the model is biased towards recall (recall is not punished by the occurance of false positives) over precision (precision is not punished the occurence of false negatives). The model was trained using an early stopper based on maximization of the f1 score (calculated from the model performance on the validation set) with a pacients of 50 epochs. The final f1 score of the model's performance on the validation set was 000 with an accuracy of 00000 and loss of 0000000. The accuracy and loss on the model on the training data as 000000 and 0000000. The figure found in the data directory is a plot of comparisons of the models training vs valdiation accuracy and loss. It also includes a plot of the f1 scores the model outptued over the course of the training. 
