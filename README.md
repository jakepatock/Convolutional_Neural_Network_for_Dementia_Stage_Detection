# Convolutional_Neural_Network_for_Dementia_Stage_Detection

This project involves a CNN model used for predicting the stage of dementia in patients based on transverse MRI brain images. The dataset used by this model was sourced from Kaggle (link: https://www.kaggle.com/datasets/sachinkumar413/alzheimer-mri-dataset). This dataset comprises 6,400 128x128-pixel images of transverse brain MRI scans from patients at varying dementia stages. The dataset consists of four classes: Class 1 (mildly demented) includes 896 images; Class 2 (moderately demented) has 64 images; Class 3 (non-demented) comprises 3,200 images; and Class 4 (very mildly demented) contains 2,240 images. Notably, the dataset is imbalanced across its class representation.

The dataset was divided into 80% for training and 20% for validation, and the images were converted into a single grayscale channel tensor. A batch size of 16 images per batch was utilized in the data loader. The CNN structure consisted of 5 convolutional layers with a max-pooling layer interspersed among them. The channel sizes progressed in the order of 1, 64, 128, 256, 512, and 512. The final pooling layer was flattened and connected to three fully connected linear layers. After the first two linear layers, dropout of 0.5 was introduced to prevent overfitting. The sizes of these linear layers were as follows: 8192 neurons, 1024 neurons, 256 neurons, and finally 4 neurons. Batch normalization was also applied to the output of each layer (both convolutional layers and fully connected linear layers) before the activation fuction (ReLU) was applied.

The model utilized cross-entropy loss for multi-class classification and was optimized using the Adam optimizer. Evaluation was performed using a weighted F1 score, biased towards recall due to the medical nature of the data. The model prioritized avoiding false negatives, as they might lead to patients' symptom dismissal and delayed dementia diagnosis, potentially impacting treatment effectiveness. False positives were deemed less damaging, leading to closer patient inspection and continued testing which results in little harm to the pacient.

Training incorporated an early stopper (with a pacients of 50 epochs) based on maximizing the F1 score on the validation set. The final F1 score on the validation set was 0.996875, with an accuracy of 0.996875 and loss of 0.02079408180675042. The model achieved an accuracy and loss of 0.9986328125 and 0.003162659881454785 on the training data. The figures in the data/plots directory showcase a comparison plots of the model's training and validation accuracy and loss, along with a plot of the F1 scores. The different plots corresponds to differing batch sizes used in the dataloader to see how the convergence of the model would be affected. The model had the most stable convergence to the lowest loss when using the batch size of 16 (even though the f1 score for the 16 size batch minisculely lower than the max f1 for the 64 batch model).as
